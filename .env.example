# =============================================================================
# GeoTime Application Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your actual values
# Server-side environment variables (keep secure, never expose to frontend)

# =============================================================================
# MAPBOX CONFIGURATION
# =============================================================================
# Get these from: https://account.mapbox.com/access-tokens/
# Public token (pk.*) - safe to use in frontend
MAPBOX_PUBLIC_TOKEN=pk.your_mapbox_public_token_here

# Secret token (sk.*) - NEVER expose to frontend, used for server-side geocoding
MAPBOX_SECRET_TOKEN=sk.your_mapbox_secret_token_here

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Choose your LLM provider: openai | anthropic | google | groq
LLM_PROVIDER=openai

# -----------------------------------------------------------------------------
# OpenAI Configuration
# -----------------------------------------------------------------------------
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_MAX_TOKENS=150
OPENAI_TEMPERATURE=0.7
OPENAI_BASE_URL=https://api.openai.com/v1

# -----------------------------------------------------------------------------
# Anthropic Claude Configuration
# -----------------------------------------------------------------------------
# Get from: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-haiku-20240307
ANTHROPIC_MAX_TOKENS=150
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_BASE_URL=https://api.anthropic.com/v1

# -----------------------------------------------------------------------------
# Google Gemini Configuration
# -----------------------------------------------------------------------------
# Get from: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here
GOOGLE_MODEL=gemini-1.5-flash
GOOGLE_MAX_TOKENS=150
GOOGLE_TEMPERATURE=0.7
GOOGLE_BASE_URL=https://generativelanguage.googleapis.com/v1

# -----------------------------------------------------------------------------
# Groq Configuration
# -----------------------------------------------------------------------------
# Get from: https://console.groq.com/keys
GROQ_API_KEY=gsk_your_groq_api_key_here
GROQ_MODEL=llama3-8b-8192
GROQ_MAX_TOKENS=150
GROQ_TEMPERATURE=0.7
GROQ_BASE_URL=https://api.groq.com/openai/v1

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
# Server port
PORT=3001

# Node environment (development | production)
NODE_ENV=development

# Allowed CORS origins (comma-separated)
ALLOWED_ORIGINS=http://localhost:5173,http://127.0.0.1:5173,http://localhost:8080


VITE_API_BASE_URL=http://localhost:3001/api
# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================
# Rate limiting (requests per 15-minute window)
RATE_LIMIT_MAX=100

# Trust proxy (set to true if behind reverse proxy like nginx, cloudflare)
TRUST_PROXY=false

# Maximum request body size
MAX_REQUEST_SIZE=1mb

# =============================================================================
# FRONTEND CONFIGURATION (.env.local for frontend)
# =============================================================================
# These should be in a separate .env.local file in the root directory for frontend
# VITE_API_BASE_URL=http://localhost:3001/api

# =============================================================================
# DEPLOYMENT NOTES
# =============================================================================
# For Vercel deployment:
# 1. Set all these variables in your Vercel dashboard
# 2. Ensure NODE_ENV=production for production deployments
# 3. Update ALLOWED_ORIGINS to include your production domain
# 4. Consider using different API keys for production vs development

# For Docker deployment:
# 1. Create a .env file with these variables
# 2. Mount it as a volume or pass via docker-compose environment section
# 3. Ensure proper security for the .env file (chmod 600)

# =============================================================================
# SECURITY BEST PRACTICES
# =============================================================================
# 1. Never commit real API keys to version control
# 2. Use different API keys for development and production
# 3. Regularly rotate your API keys
# 4. Monitor API usage and set up billing alerts
# 5. Use environment-specific configuration for CORS origins
# 6. Enable rate limiting in production
# 7. Use HTTPS in production
# 8. Consider using a secrets management service for production